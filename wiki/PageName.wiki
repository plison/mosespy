=!MosesPy=

 * Current version: 0.2
 * Main developer: [http://folk.uio.no/plison Pierre Lison] ([mailto:plison@ifi.uio.no plison@ifi.uio.no])


The !MosesPy interface is a Python package designed to ease the use of the Moses toolkit for statistical machine translation.  It contains a set of methods for training, tuning and evaluating SMT models. The interface relies on 3 third-party tools: the [http://statmt.org/moses Moses] toolkit itself (and its set of processing scripts), the multi-threaded GIZA ([http://www.kyloo.net/software/doku.php/mgiza:overview MGIZA++]), and the [https://hlt.fbk.eu/technologies/irstlm-irst-language-modelling-toolkit IRSTLM] language modelling toolkit.

!MosesPy is released under an [http://opensource.org/licenses/MIT MIT license]. Note that this license only 
applies to the !MosesPy package, not the third-party tools!


== How to install !MosesPy==

In order to compile the code for these third-party libraries, simply run the `install.py` script:
{{{
	$ python -m mosespy.install
}}}
	
Note that the installation script will only work for reasonably standard
configurations. If the script fails, you will have to compile the code
manually (see the instructions on the Moses website and the documentation for MGIZA++ and IRSTLM for details).

== Running !MosesPy==

Once Moses, MGIZA++ and IRSTLM are compiled, you are ready to configure
and run translation experiments.  A simple example of experiment is
shown in the file `run_experiment.py`.  Of course, you will need to download  the data to run the experiment:
 * the training data is available at [http://www.statmt.org/wmt13/training-parallel-nc-v8.tgz]
 * the tuning and testing data are available at [http://www.statmt.org/wmt12/dev.tgz]

Once you have downloaded the data, modify the corresponding paths in `run_experiment.py`, and run the script:
{{{
	$ python run_experiment.py
}}}
 
As you might notice, this experiment is a replica of the baseline setup described in the Moses [http://www.statmt.org/moses/?n=Moses.Baseline Baseline system], but is  substantially easier to run.  The final BLEU score at the end of this experiment example should be around 23.50.
 
 